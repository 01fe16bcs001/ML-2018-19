{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Linear regression is a linear approach to modelling the relationship between a scalar response (or dependent variable) and one or more explanatory variables (or independent variables).In linear regression, the relationships are modeled using linear predictor functions whose unknown model parameters are estimated from the data.\n",
    "\n",
    "In order to explain the differences between alternative approaches to estimating the parameters of a model, let's take a look at a concrete example: Ordinary Least Squares (OLS) Linear Regression. The illustration below shall serve as a quick reminder to recall the different components of a simple linear regression model:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![alt text](1.png \"Title\") with ![alt text](2.png \"Title\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In Ordinary Least Squares (OLS) Linear Regression, our goal is to find the line (or hyperplane) that minimizes the vertical offsets. Or, in other words, we define the best-fitting line as the line that minimizes the sum of squared errors (SSE) or mean squared error (MSE) between our target variable (y) and our predicted output over all samples i in our dataset of size n.\n",
    "![alt text](3.png \"Title\")\n",
    "\n",
    "Now, we can implement a linear regression model for performing ordinary least squares regression using one of the following approaches:\n",
    "1. Solving the model parameters analytically (closed-form equations)\n",
    "2. Using an optimization algorithm (Gradient Descent, Stochastic Gradient Descent, Newton's Method, Simplex Method, etc.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. GRADIENT DESCENT:\n",
    "Using the Gradient Decent (GD) optimization algorithm, the weights are updated incrementally after each epoch (= pass over the training dataset). The cost function J(⋅), the sum of squared errors (SSE), can be written as: ![alt text](4.png \"Title\")\n",
    "The magnitude and direction of the weight update is computed by taking a step in the opposite direction of the cost gradient ![alt text](5.png \"Title\") where η is the learning rate. The weights are then updated after each epoch via the following update rule: ![alt text](6.png \"Title\")\n",
    "where Δw is a vector that contains the weight updates of each weight coefficient w, which are computed as follows:![alt text](7.png \"Title\")\n",
    "Essentially, we can picture GD optimization as a hiker (the weight coefficient) who wants to climb down a mountain (cost function) into a valley (cost minimum), and each step is determined by the steepness of the slope (gradient) and the leg length of the hiker (learning rate). Considering a cost function with only a single weight coefficient, we can illustrate this concept as follows:![alt text](8.png \"Title\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. STOCHASTIC GRADIENT DESCENT (SGD):\n",
    "In GD optimization, we compute the cost gradient based on the complete training set; hence, we sometimes also call it batch GD. In case of very large datasets, using GD can be quite costly since we are only taking a single step for one pass over the training set -- thus, the larger the training set, the slower our algorithm updates the weights and the longer it may take until it converges to the global cost minimum (note that the SSE cost function is convex). In Stochastic Gradient Descent (SGD; sometimes also referred to as iterative or on-line GD), we don't accumulate the weight updates as we've seen above for GD:![alt text](9.png \"Title\")Instead, we update the weights after each training sample: ![alt text](10.png \"Title\")Here, the term \"stochastic\" comes from the fact that the gradient based on a single training sample is a \"stochastic approximation\" of the \"true\" cost gradient. Due to its stochastic nature, the path towards the global cost minimum is not \"direct\" as in GD, but may go \"zig-zag\" if we are visualizing the cost surface in a 2D space."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
